install.packages(c("callr", "cli", "cpp11", "e1071", "foreach", "iterators", "tibble"))
setwd("/Users/udayshankar/Desktop/Analytics Edge/Week 5")
getwd()
cat("/f")
cat(/f)
cat("\f")
tweets <- read.csv(file.choose())
tweets <- read.csv(file.choose(),stringsAsFactors = FALSE)
str(tweets)
summary(tweets)
tweets$negative <- as.factor(tweets$Avg <= -1)
table(tweets$negative)
install.packages(c("tm","SnowballC"))
library(c("tm","SnowballC"))
library(tm)
library(SnowballC)
corpus <- Corpus(VectorSource(tweets$Tweet))
corpus
corpus[[1]]
corpus[[1]]$content
corpus <- tm_map(corpus,tolower)
corpus[[1]]$content
corpus <- tm_map(corpus,removePunctuation)
corpus[[1]]$content
corpus <- tm_map(corpus,removeWords,c("apple",stopwords("english")))
corpus[[1]]$content
corpus <- tm_map(corpus,stemDocument)
corpus[[1]]$content
frequencies <- DocumentTermMatrix(corpus)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies,lowfreq = 20)
sparse <- removeSparseTerms(frequencies,0.995)
sparse
tweetsparse <- as.data.frame(as.matrix(sparse))
colnames(tweetsparse) = make.names(colnames(tweetsparse))
tweetsparse$negative <- tweets$negative
library(caTools)
findFreqTerms(frequencies,lowfreq = 100)
set.seed(123)
split <- sample.split(tweetsparse$negative,SplitRatio = 0.7)
train <- subset(tweetsparse,split == TRUE)
test <- subset(tweetsparse,split == FALSE)
library(rpart)
library(rpart.plot)
tweetcart <- rpart(negative ~ ., data = train, method = "class")
prp(tweetcart)
summary(tweetcart)
predictcart <- predict(tweetcart,test,method = "class")
table(test$negative,predictcart)
predictcart <- predict(tweetcart,test,type = "class")
table(test$negative,predictcart)
tweetlog <- glm(negative~.,data = train,family = "binomial")
predictions = predict(tweetlog, newdata=test, type="response")
table(test$negative,predictions>=0.5)
(251+35)/(251+49+20+45)
table(test$negative,predictions>0.5)
rm(list = ls())
emails <- read.csv(file.choose(),stringsAsFactors = FALSE)
str(emails)
strwrap(emails$email[1])
strwrap(emails$email[2])
emails$responsive
emails$responsive[2]
table(emails$responsive == 1)
table(emails$responsive)
corpus <- Corpus(VectorSource(emails$email))
strwrap(corpus[[1]])
corpus <- tm_map(corpus,tolower)
corpus <- tm_map(corpus,removePunctuation)
corpus <- tm_map(corpus,removeWords,stopwords("english"))
corpus <- tm_map(corpus,stemDocument)
strwrap(corpus[[1]])
dtm <- DocumentTermMatrix(corpus)
dtm <- removeSparseTerms(corpus,0.97)
dtm <- removeSparseTerms(dtm,0.97)
labelterms <- as.data.frame(as.matrix(dtm))
labelterms$responsive <- emails$responsive
RNGkind(kind = "Rounding")
RNGkind(sample.kind = "Rounding")
set.seed(144)
split <- sample.split(labelterms$responsive,SplitRatio = 0.7)
train <- subset(labelterms,split == TRUE)
test <- subset(labelterms,split == FALSE)
emailcart <- rpart(responsive ~ ., data = train, method = "class")
prp(emailcart)
prp(emailcart,roundint = FALSE)
pred <- predict(emailcart,test)
table(test$responsive,pred>=0.5)
table(test$responsive,pred[,2]>=0.5)
table(test$responsive)
predrocr <- prediction(pred[,2],test$responsive)
library(ROCR)
predrocr <- prediction(pred[,2],test$responsive)
perfrocr <- performance(predrocr,"tpr","fpr")
plot(perfrocr,colorize = TRUE)
rm(list = ls())
install.packages(c("digest", "recipes"))
emails <- read.csv(file.choose(),stringsAsFactors = FALSE)
table(emails$spam)
strwrap(emails$text[1:10,])
strwrap(emails$text[1:10])
max(nchar(emails$text))
which.min(nchar(emails$text))
corpus <- Corpus(VectorSource(emails$text))
corpus <- tm_map(corpus,tolower)
corpus <- tm_map(corpus,removePunctuation)
corpus <- tm_map(corpus,removeWords,stopwords("english"))
corpus <- tm_map(corpus,stemDocument)
strwrap(corpus[[1]])
dtm <- DocumentTermMatrix(corpus)
length(stopwords("english"))
dtm
spdtm <- DocumentTermMatrix(corpus)
spdtm <- removeSparseTerms(corpus,0.95)
spdtm <- removeSparseTerms(spdtm,0.95)
spdtm
emailsparse <- as.data.frame(as.matrix(spdtm))
make.names(emailsparse)
View(emailsparse)
which.max(colSums(emailsparse))
emailsparse$spam <- emails$spam
findFreqTerms(spdtm,lowfreq = 5000)
colnames(emailsparse) <- make.names(colnames(emailsparse))
emailsparse$spam <- emails$spam
findFreqTerms(spdtm,lowfreq = 5000)
findFreqTerms(cols=Sums(emailsparse),lowfreq = 5000)
which.min(colSums(emailsparse))<=5000
which(colSums(emailsparse))<=5000
sum(colSums(emailsparse))<=5000
count.fields(colSums(emailsparse))<=5000
findFreqTerms(emailsparse,lowfreq = 5000)
findFreqTerms(emailsparse$spam,lowfreq = 5000)
findFreqTerms(dtm,lowfreq = 5000)
colSums(subset(emailsparse,spam == 0))
colSums(subset(emailsparse,spam == 0))>5000
sort(colSums(subset(emailsparse,spam == 0)))
sort(colSums(subset(emailsparse,spam == 0)))
ncol(colSums(subset(emailsparse,spam == 0)))
table(colSums(subset(emailsparse,spam == 0)))
table(colSums(subset(emailsparse,spam == 0)))>1000
emailsparse$spam <- as.factor(emailsparse$spam)
RNGkind(sample.kind = "Rounding")
set.seed(123)
spl <- sample.split(emailsparse$spam,SplitRatio = 0.7)
train <- subset(emailsparse,spl == TRUE)
test <- subset(emailsparse,spl == FALSE)
spamlog <- glm(spam~., data = train,family = "binomial")
spamcart <- rpart(spam~.,data = train,method = "class")
library(randomForest)
set.seed(123)
spamforest <- randomForest(spam~.,data = train)
table(spamlog[,2]<0.00001)
spamlog[,2]<0.00001
predict(spamlog,train,type = "response")
predict(spamlog<0.00001,train,type = "response")
spamlog$fitted.values
spamlog$fitted.values<0.00001
table(spamlog$fitted.values<0.00001)
table(spamlog$fitted.values<0.99999)
table(0.00001<spamlog$fitted.values<0.99999)
0.00001<table(spamlog$fitted.values)<0.99999
range(spamlog$fitted.values)
table(spamlog$fitted.values>0.00001&spamlog$fitted.values<0.99999)
summary(spamlog)
prp(spamcart)
spampred <- predict(spamlog,train,type = "response")
table(train$spam,spampred>0.5)
(3052+954)/nrow(train)
predrocrlog <- prediction(spampred,train$spam)
perfrocrlog <- performance(predrocrlog,"tpr","fpr")
performance(predrocrlog,"auc")@y.values
spamcartpred <- predict(spamcart,train,type = "class")
table(train$spam,spamcartpred>0.5)
table(train$spam,spamcartpred[,2]>=0.5)
table(train$spam,spamcartpred)
(2885+894)/nrow(train)
predrocrcart <- prediction(spamcartpred,train$spam)
spamcartpred <- predict(spamcart,train)
predrocrcart <- prediction(spamcartpred,train$spam)
pred <- predict(spamcart,train)
predrocrcart <- prediction(spamcartpred[,2],train$spam)
performance(predrocrcart,"auc")@y.values
spamrfpred <- predict(spamforest,train)
table(train$spam,spamrfpred)
(3046+958)/nrow(train)
spamrfpred <- predict(spamforest,train,type = "prob")
predrocrrf <- prediction(spamrfpred[,2],train$spam)
performance(predrocrrf,"auc")@y.values
spampred <- predict(spamlog,test,type = "response")
table(train$spam,spampred>0.5)
table(test$spam,spampred>0.5)
(1257+376)/nrow(test)
predrocrlog <- prediction(spampred,test$spam)
performance(predrocrlog,"auc")@y.values
spamcartpred <- predict(spamcart,test,type = "class")
table(test$spam,spamcartpred)
(1228+386)/nrow(test)
predrocrcart <- prediction(spamcartpred[,2],test$spam)
spamcartpred <- predict(spamcart,test)
predrocrcart <- prediction(spamcartpred[,2],test$spam)
performance(predrocrcart,"auc")@y.values
spamrfpred <- predict(spamforest,test,type = "prob")
predrocrrf <- prediction(spamrfpred[,2],train$spam)
predrocrrf <- prediction(spamrfpred[,2],test$spam)
performance(predrocrrf,"auc")@y.values
table(test$spam,spamrfpred)
table(test$spam,spamrfpred[,2])
predrocrrf <- prediction(spamrfpred,test$spam)
predrocrrf <- prediction(spamrfpred[,2],test$spam)
table(test$spam,spamrfpred[,2])
table(test$spam,spamrfpred[,2]>=0.5)
(1290+385)/nrow(test)
rm(list = ls())
trial <- read.csv(file.choose(),stringsAsFactors = FALSE)
str(trial)
max(nchar(trial$abstract))
(nchar(trial$abstract)) == 0
table(nchar(trial$abstract) == 0)
which.min(nchar(trial$title))
trial[1258,]
trial$title[1258]
corpustitle <- Corpus(VectorSource(trial$title))
corpusabstract <- Corpus(VectorSource(trial$abstract))
corpustitle <- tm_map(corpustitle,tolower)
corpustitle <- tm_map(corpustitle,removePunctuation)
corpustitle <- tm_map(corpustitle,removeWords,stopwords("english"))
corpustitle <- tm_map(corpustitle,stemDocument)
corpusabstract <- tm_map(corpusabstract,tolower)
corpusabstract <- tm_map(corpusabstract,removePunctuation)
corpusabstract <- tm_map(corpusabstract,removeWords,stopwords("english"))
corpusabstract <- tm_map(corpusabstract,stemDocument)
dtmtitle <- DocumentTermMatrix(corpustitle)
dtmabstract <- DocumentTermMatrix(corpusabstract)
dtmtitle <- removeSparseTerms(dtmtitle,0.95)
dtmabstract <- removeSparseTerms(dtmabstract,0.95)
dtmtitle <- as.data.frame(as.matrix(dtmtitle))
dtmabstract <- as.data.frame(as.matrix(dtmabstract))
max(colSums(dtmabstract))
which.max(colSums(dtmabstract))
colnames(dtmtitle) <- paste0("T",colnames(dtmtitle))
colnames(dtmabstract) <- paste0("A",colnames(dtmabstract))
dtm <- cbind(dtmtitle,dtmabstract)
RNGkind(sample.kind = "Rounding")
set.seed(144)
spl <- sample.split(dtm,SplitRatio = 0.7)
train <- subset(dtm,spl == TRUE)
test <- subset(dtm,spl == FALSE)
dtm$trial <- trial$trial
RNGkind(sample.kind = "Rounding")
set.seed(144)
spl <- sample.split(dtm,SplitRatio = 0.7)
train <- subset(dtm,spl == TRUE)
test <- subset(dtm,spl == FALSE)
table(train$trial)
726/(726+574)
trialcart <- rpart(trial~.,data = train,method = "class")
prp(trialcart)
cartpred <- predict(trialcart,train)
table(train$trial,cartpred[,2])
table(train$trial,cartpred)
table(train$trial,cartpred[,2])
predtrain <- predict(trialcart)[,2]
summary(predtrain)
table(train$trial,cartpred>=0.5)
table(train$trial,cartpred[,2]>=0.5)
(634+422)/(634+422+92+152)
634/(634+92)
422(422+152)
422/(422+152)
table(train$trial,cartpred>=0.5)
predtest <- predict(trialcart)[,2]
table(test$trial,predtest>=0.5)
table(test$trial,predtest[,2]>=0.5)
predtest <- predict(trialcart,test)
table(test$trial,predtest>=0.5)
table(test$trial,predtest[,2]>=0.5)
(270+168)/(270+168+47+75)
predtest <- predict(trialcart,test)[,2]
table(test$trial,predtest>=0.5)
predrocrrf <- prediction(predtest,test$trial)
performance(predrocrrf,"auc")@y.values
wiki <- read.csv(file.choose(),stringsAsFactors = FALSE)
str(wiki)
sum(wiki$Vandal == 1)
corpus <- Corpus(VectorSource(wiki$Added))
corpus <- tm_map(corpus,removeWords,stopwords("english"))
length(stopwords("english"))
corpus <- tm_map(corpus,stemDocument)
dtmadded <- DocumentTermMatrix(corpus)
dtmadded
sparseadded <- removeSparseTerms(dtmadded,0.97)
sparseadded
sparseadded <- removeSparseTerms(dtmadded,0.70)
sparseadded
0.3/100
sparseadded <- removeSparseTerms(dtmadded,0.997)
sparseadded
wordsadded <- as.data.frame(as.matrix(sparseadded))
colnames(wordsadded) <- paste0("A",colnames(wordsadded))
corpus2 <- Corpus(VectorSource(wiki$Removed))
corpus2 <- tm_map(corpus2,removeWords,stopwords("english"))
corpus2 <- tm_map(corpus2,stemDocument)
dtmremoved <- DocumentTermMatrix(corpus2)
sparseremoved <- removeSparseTerms(dtmremoved,0.997)
wordsremoved <- as.data.frame(as.matrix(sparseremoved))
colnames(wordsremoved) <- paste0("B",colnames(wordsremoved))
colSums(wordsremoved)
sum(colnames(wordsremoved))
ncol(wordsremoved)
wikiwords <- cbind(wordsadded,wordsremoved)
wikiwords$vandal <- wiki$Vandal
RNGkind(sample.kind = "Rounding")
set.seed(123)
spl <- sample.split(wikiwords$vandal,SplitRatio = 0.7)
train <- subset(wikiwords,spl == TRUE)
test <- subset(wikiwords,spl == FALSE)
table(test$vandal)
618/(618+545)
wikicart <- rpart(vandal~.,train,method = "class")
predwiki <- predict(wikicart,test,type = "class")
table(test$vandal,predwiki)
(614+19)/(614+4+19+526)
prp(wikicart)
prp(wikicart,roundint = FALSE)
wikiwords2 <- wikiwords
wikiwords2$https <- ifelse(grepl("http",wiki$Added,fixed=TRUE), 1, 0)
summary(wikiwords2)
summary(wikiwords2$https)
sum(wikiwords2$https == 1)
wikitrain <- subset(wikiwords2,spl==TRUE)
wikitest <- subset(wikiwords2,spl==FALSE)
wikicart2 <- rpart(https~.,wikitrain,method = "class")
wikipred2 <- predict(wikicart2,wikitest,type = "class")
table(wikitest$https,wikipred2)
(1109+2)/(1109+54)
wikicart2 <- rpart(vandal~.,wikitrain,method = "class")
wikipred2 <- predict(wikicart2,wikitest,type = "class")
table(wikitest$vandal,wikipred2)
(605+64)/(605+64+13+481)
numwordsadded <- nrow(wordsadded)
numwordsremoved <- nrow(wordsremoved)
wikiwords2$numwordsadded <- rowSums(as.matrix(dtmadded))
wikiwords2$numwordsremoved <- rowSums(as.matrix(dtmremoved))
mean(wikiwords2$numwordsadded)
wikipred2 <- predict(wikicart2,test,type = "class")
wikipred2 <- predict(wikicart2,wikitest,type = "class")
table(wikitest$vandal,wikipred2)
table(wikitest$https,wikipred2)
(1086+54)/(1086+54+23)
wikiwords3 <- wikiwords2
wikiwords3$minor <- wiki$Minor
wikiwords3$loggedin <- wiki$Loggedin
wikitrain1 <- subset(wikiwords3,spl==TRUE)
wikitest1 <- subset(wikiwords3,spl==FALSE)
wikicart3 <- rpart(vandal~.,wikitrain1,method = "class")
wikipred3 <- predict(wikicart3,wikitest1,type = "class")
table(wikitest1$vandal,wikipred3,type = "class")
table(wikitest1$vandal,wikipred3[,2]>=0.5)
table(wikitest1$vandal,wikipred3>=0.5)
table(wikitest1$vandal,wikipred3)
(595+241)/(595+241+23+304)
prp(wikicart3)
rm(list = ls())
